{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3915fbb3",
   "metadata": {},
   "source": [
    "# Evaluating Your Own Custom Dataset with ibbi.Evaluator\n",
    "This notebook demonstrates how to evaluate your **own custom dataset** using the `ibbi.Evaluator`.\n",
    "\n",
    "A common use case, as highlighted by our reviewer, is an ecologist who has their own set of annotated images. This tutorial shows you what data format the `ibbi.Evaluator` expects and how to run an evaluation on it.\n",
    "\n",
    "### The Required Data Structure\n",
    "\n",
    "The `ibbi.Evaluator` expects an **iterable (like a list) of dictionaries**. Each dictionary in the list represents one image and its annotations.\n",
    "\n",
    "Each dictionary **must** conform to the following structure:\n",
    "\n",
    "```python\n",
    "[\n",
    "    {\n",
    "        \"image\": <PIL.Image.Image object>,\n",
    "        \"objects\": {\n",
    "            \"category\": [\"species_label_1\", \"species_label_2\"],\n",
    "            \"bbox\": [\n",
    "                [x1, y1, w1, h1],  # BBox 1 in [x_min, y_min, width, height] format\n",
    "                [x2, y2, w2, h2]   # BBox 2 in [x_min, y_min, width, height] format\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"image\": <PIL.Image.Image object_2>,\n",
    "        \"objects\": { ... } # Annotations for the second image\n",
    "    }\n",
    "    # ... and so on for all images in your dataset\n",
    "]\n",
    "```\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "  * `\"image\"`: Must be a `PIL.Image.Image` object. You can load this from a file path using `Image.open(your_path)`.\n",
    "  * `\"objects\"`: Must be a dictionary.\n",
    "  * `\"category\"`: A `list` of strings, where each string is the species name for an object.\n",
    "  * `\"bbox\"`: A `list` of lists. Each inner list must be in `[x_min, y_min, width, height]` format.\n",
    "\n",
    "How you load your data (from a CSV, JSON, or XML files) is up to you, but it **must** be formatted into this list of dictionaries before being passed to the `Evaluator`.\n",
    "\n",
    "-----\n",
    "\n",
    "### 1\\. Create a Mock Custom Dataset\n",
    "\n",
    "To demonstrate, we will create an artificial dataset from scratch that matches this structure. We'll generate a few `PIL.Image` objects, draw some \"beetles\" (rectangles) on them, and store them in our required list format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1379e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import ibbi\n",
    "\n",
    "# --- 1. Create an artificial dataset ---\n",
    "print(\"Creating a mock custom dataset in the required format...\")\n",
    "\n",
    "# This will be our final dataset, a list of dictionaries\n",
    "my_custom_dataset = []\n",
    "\n",
    "# Get some real species names to use as labels\n",
    "species_list = [\"Ips_acuminatus\", \"Hylurgus_ligniperda\", \"Tomicus_destruens\", \"Dryocoetes_autographus\"]\n",
    "\n",
    "# --- Image 1 (One Beetle) ---\n",
    "img1 = Image.new(\"RGB\", (640, 480), color=\"#334433\")  # A dark green image\n",
    "draw1 = ImageDraw.Draw(img1)\n",
    "label1 = \"Ips_acuminatus\"\n",
    "bbox1 = [100, 150, 50, 80]  # [x, y, w, h]\n",
    "# Draw the rectangle: [x1, y1, x2, y2]\n",
    "draw1.rectangle([bbox1[0], bbox1[1], bbox1[0] + bbox1[2], bbox1[1] + bbox1[3]], outline=\"yellow\", width=3)\n",
    "draw1.text((bbox1[0], bbox1[1] - 15), label1, fill=\"yellow\")\n",
    "\n",
    "# Add to our dataset\n",
    "my_custom_dataset.append({\"image\": img1, \"objects\": {\"category\": [label1], \"bbox\": [bbox1]}})\n",
    "\n",
    "# --- Image 2 (Two Beetles) ---\n",
    "img2 = Image.new(\"RGB\", (640, 480), color=\"#554433\")  # A dark brown image\n",
    "draw2 = ImageDraw.Draw(img2)\n",
    "# Object 1\n",
    "label2a = \"Hylurgus_ligniperda\"\n",
    "bbox2a = [200, 250, 40, 60]\n",
    "draw2.rectangle([bbox2a[0], bbox2a[1], bbox2a[0] + bbox2a[2], bbox2a[1] + bbox2a[3]], outline=\"cyan\", width=3)\n",
    "draw2.text((bbox2a[0], bbox2a[1] - 15), label2a, fill=\"cyan\")\n",
    "# Object 2\n",
    "label2b = \"Tomicus_destruens\"\n",
    "bbox2b = [400, 100, 55, 55]\n",
    "draw2.rectangle([bbox2b[0], bbox2b[1], bbox2b[0] + bbox2b[2], bbox2b[1] + bbox2b[3]], outline=\"magenta\", width=3)\n",
    "draw2.text((bbox2b[0], bbox2b[1] - 15), label2b, fill=\"magenta\")\n",
    "\n",
    "# Add to our dataset\n",
    "my_custom_dataset.append({\"image\": img2, \"objects\": {\"category\": [label2a, label2b], \"bbox\": [bbox2a, bbox2b]}})\n",
    "\n",
    "# --- Image 3 (One Beetle, different species) ---\n",
    "img3 = Image.new(\"RGB\", (640, 480), color=\"#444444\")  # A gray image\n",
    "draw3 = ImageDraw.Draw(img3)\n",
    "label3 = \"Dryocoetes_autographus\"\n",
    "bbox3 = [300, 200, 70, 40]\n",
    "draw3.rectangle([bbox3[0], bbox3[1], bbox3[0] + bbox3[2], bbox3[1] + bbox3[3]], outline=\"red\", width=3)\n",
    "draw3.text((bbox3[0], bbox3[1] - 15), label3, fill=\"red\")\n",
    "\n",
    "# Add to our dataset\n",
    "my_custom_dataset.append({\"image\": img3, \"objects\": {\"category\": [label3], \"bbox\": [bbox3]}})\n",
    "\n",
    "print(f\"Mock dataset created with {len(my_custom_dataset)} images.\")\n",
    "print(\"\\nShowing the first mock image:\")\n",
    "my_custom_dataset[0][\"image\"].show()  # This will open the image in a new window\n",
    "\n",
    "print(\"\\nVerifying data structure for the first image:\")\n",
    "print(my_custom_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d3c7ed",
   "metadata": {},
   "source": [
    "### 2\\. Create a Model and Evaluator\n",
    "\n",
    "This step is the same as before. We load a pre-trained `ibbi` model and initialize the `Evaluator` with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425918c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate the multi-class YOLOv8 model.\n",
    "model = ibbi.create_model(\"yolov8x_bb_multi_class_detect_model\", pretrained=True)\n",
    "evaluator = ibbi.Evaluator(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73858c96",
   "metadata": {},
   "source": [
    "### 3\\. Unified Object Classification Performance (on Custom Data)\n",
    "\n",
    "Now, we pass our `my_custom_dataset` list directly to the evaluator's methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e73ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Evaluating Object Classification Performance on Custom Dataset ---\")\n",
    "# We can test across multiple IoU thresholds for the mAP calculation.\n",
    "iou_thresholds = np.arange(0.5, 1.0, 0.05)\n",
    "\n",
    "# Pass our custom list directly to the evaluator\n",
    "performance = evaluator.object_classification(my_custom_dataset, iou_thresholds=iou_thresholds)\n",
    "\n",
    "# --- Display Key Metrics ---\n",
    "print(\"\\n--- Key Object-Classification Performance Metrics (Custom Dataset) ---\")\n",
    "# The 'per_class_AP_at_last_iou' will show AP for our mock species\n",
    "print(f\"Overall mAP: {performance['mAP']:.4f}\")\n",
    "print(\"Per-class AP scores:\")\n",
    "print(performance[\"per_class_AP_at_last_iou\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5dabd5",
   "metadata": {},
   "source": [
    "### 4\\. Embedding Quality (on Custom Data)\n",
    "\n",
    "We can also evaluate the embedding quality using our custom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901cf539",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Evaluating Embedding Quality on Custom Dataset ---\")\n",
    "# This will perform UMAP, HDBSCAN, and then calculate clustering metrics.\n",
    "# We'll use the 'object' level to get embeddings for each bounding box.\n",
    "embedding_performance = evaluator.embeddings(my_custom_dataset, evaluation_level=\"object\", min_cluster_size=2)\n",
    "\n",
    "# --- Display Key Embedding Metrics ---\n",
    "print(\"\\n--- Key Embedding Performance Metrics (Custom Dataset) ---\")\n",
    "print(\"\\nInternal Validation (how good are the clusters?):\")\n",
    "print(embedding_performance[\"internal_cluster_validation\"])\n",
    "print(\"\\nExternal Validation (do clusters match true labels?):\")\n",
    "print(embedding_performance[\"external_cluster_validation\"])\n",
    "print(\"\\nMantel Correlation (do clusters match phylogeny?):\")\n",
    "# Note: The Mantel test requires at least 3 unique species with valid data.\n",
    "# Our mock dataset has 4 species, so it should run.\n",
    "print(embedding_performance.get(\"mantel_correlation\", \"Not calculated (requires >= 3 species)\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IBBI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
